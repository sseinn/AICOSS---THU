# feature engineering

3. scailing

대부분의 데이터가 범위들이 다르고 단위가 다르다. 단위와 범위가 다른 경우 데이터끼리 직접적인 비교가 불가능하다. 이런 문제를 해결하기 위해 scailing을 진행한다.

### normalization (정규화)

![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/b1ad4853-98e7-47b1-a4f0-06ab03afa666)


데이터를 0과 1 사이의 값으로 변화하여 이사이의 영향력이 커지므로 정규화후 이상치를 다루는 것이 좋다. 

### standardization


![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/82f92653-fdca-4dcd-90a6-52c11ede5aa1)

값을디 정규분포를 따른다고 가정하고 값들을 0의 평균 1의 표준편차를 갖도록 변화해주는 것. 표준화를 해주면 정규화처럼 특성값의 범위가 0~1 사이로 균일하게 바뀌지는 않는다. 

# relu가 sigmooid보다 선호되는 이유

1. 계산 효율성

활성화 함수의 계산 효율성은 입력이 주어졌을 때 출력을 얼마나 빨리 계산할 수 있느냐다. 대규모 데이터셋이나 복잡한 모델을 다룰 때는 당연히 더 간단함 함수가 계산 효율성이 높다. 거런 측면에서 sigmoid는 지수 함수가 포함되기 때문에 나눗셈 같은 복잡한 수학적 연산이 필요하지만 relu는 간단하게 계산할 수 있기 때문에 계산 효율성을 높일 수 있고 이는 훈련 프로세스를 더 빠르게 만들고 최적의 값으로 수렴하는 속도를 높여줄 수 있다. 

2. gradient 소실 방지

![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/78e43830-c2f6-4d19-a04e-ea8300048a7c)


sigmoid 함수는 경사 소리 문제가 있다. 입력 값이 매우 크거나 작다면 기울기도 0에 가까워 진다. 기울기가 -에 가까워지면 가중치가 매우 느리게 업데이트되므로 학습 과정이 느려지고, 신경망이 수렴하기 어렵게 된다. local minimum에 갇히게 될 수 있다. 

relu는 양수 입력 값에 대해 일정한 기울기를 갖고 있으므로 이 문제를 방지 가능

# Mean Squared Error (MSE)

추측값에 대한 정확성을 측정하는 방법. 평균과 제곱을 이용하여 오차를 계산한다. 

MSE가 0에 가까울 수록 추측값이 원본에 가까워지기 때문에 숫자가 작을 수록 좋다.

평균 값을 뺀 후에 제곱합을 하기 때문에 특이값이 존재하면 수치가 많이 늘어난다. 

작은 오류 OK

# Mean Absolute Error (MAE) 평균 절대 오차

MAE는 데이터 예측 모델의 성능을 평가하는 데 사용되는 일반적인 평가 지표 중 하나. 

실제값과 예측값 간의 차이를 평균하여 모델의 예측 정확성을 측정

MAE = (1/n) * Σ|실제값 - 예측값|

n : 데이터 샘플의 개수

Σ : 합

모든 예측값에 대해 절대 오차를 구하고 이를 데이터 샘플 수로 나누어 평균을 계산

따라서 MAE는 예측 오차의 절대값들의 평균

MAE가 낮을수록 모델의 예측 정확성이 높다고 볼 수 있다. 

큰 오류 OK

[feature engineering](https://velog.io/@baeyuna97/Feature-engineering%EC%9D%B4%EB%9E%80)
