# Logistic Regression

사건(Event)이 발생할 가능성을 예측하는 데 사용하는 모델

특정 조건(환경)이 주어졌을 때, 사건이 일어나는지, 일어나지 않는지에 대해 다룸

예측은 0과 1로만 이루어짐

1 : 사건이 일어남

0 : 사건이 일어나지 않음

# Sigmoid Function

로지스틱 회귀 모델에 사용하는 활성화 함수는 시그모이드다. 

![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/e8c8df95-b48d-4300-9fd8-d8103a2c64a3)

```
import numpy as np
import matplotlib.pyplot as plt

x = np.arange(-6, 6, 0.1)
phi = 1 / (1 + np.exp(-x))

plt.plot(x, phi)
plt.xlabel('x')
plt.ylabel('phi')

plt.show()
```

![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/e28ec939-c08f-4144-9b4c-d5f5c8791218)


시그모이드 함수는 x값이 0일 경우 y값은 0.5라는 결과다. 

x가 0보다 크면 y는 0.5를 기준으로 긍정(사건이 발생) 결과가 나타나고 x가 0보다 작으면 y는 0.5를 기준으로 부정(사건이 발생하지 않는) 결과가 나타난ㄷ. 

y가 0.5인 경우 긍정이라고 보는 경우도 있고, 부저으로 보는 경우도 있다. 


# Linear Regression

선형회귀란 x와 y의 선형적인 관계를 구해 값을 에측하는 것

x는 변수로 어느 값이든 적용 가능

기울기 a와 절편 b는 모르는 상태

-> 기울기와 절편의 값을 알게 된다면, 원하는 x값을 대입했을 때 y값을 얻을 수 있단 말과 동일하다
(y = ax + b)

a : weight

b : bias

# Mean Squared Error - MSE (평균제곱오차)

선형회귀에서 가중치와 바이어스는 MSE를 최소화 하는 방향으로 구한다. 

평균제곱오차 : 데이터의 오차를 제곱해서 데이터의 개수로 나눈 값

![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/48b5e5b4-b199-43a9-aa6e-5e0e43a5853a)

그래프에서 데이터의 값은 9이지만, 방정식의 값은 4여서 오차가 9 - 4 = 5여서 오차가 +5가 된다. 

그래프에서 데이터의 값은 3이지만, 방정식의 값은 5여서 오차가 3 - 5 = -2여서 오차가 -2가 된다. 

오차는 음수, 양수 둘다 가능하기 때문에 오차를 제곱하는 것이다. 

그리고 평균을 구하기 때문에 데이터의 개수로 오차의 합을 나눈다. 


# L2 regularization

![image](https://github.com/sseinn/AICOSS---THU/assets/143159192/23e6c2f3-f7fc-4e03-b83c-e63a46bf3533)


[참고 링크](https://itstory1592.tistory.com/8)
