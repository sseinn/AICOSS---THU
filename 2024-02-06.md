# Zero-shot classification(제로샷 분류)

레이블이 없는 텍스트를 분류하는 게 까다롭다. -> 텍스트에 레이블을 다는 것은 시간이 많이 소요되고 도메인 지식이 필요하기 때문이다. 

이러한 상황에서 Zero-shot classification 파이프라인은 매우 유용하다. 

제로샷 파이프라인은 사전 학습된 모델에 의존하지 않고도 분류 작업에 사용할 레이블을 특정할 수 있도록 한다. 

위의 예시에서 모델이 긍정(positive)과 부정(negative)의 두 레이블을 분류하는 샘플을 살펴보았는데, 제로샷 파이프라인을 통해서 어떠한 레이블 세트에 대해서도 분류 작업을 수행할 수 있다. 


### 제로샷 분류가 아닌 경우

```
from transformers import pipeline

classifier = pipeline("sentiment-analysis")
classifier("I've been waiting for a HuggingFace course my whole life.")
```

-> 레이블을 특정하지 않음

### 제로샷 분류일 경우

```
from transformers import pipeline

classifier = pipeline("zero-shot-classification")
classifier(
    "This is a course about the Transformers library",
    candidate_labels=["education", "politics", "business"],
)
```

-> 레이블을 특정 함

# Text generation(텍스트 생성)

스마트폰의 텍스트 자동 완성 기능과 유사

텍스트 생성에는 랜덤하게 결과를 생성하는 과정이 포함되어 있어 동일한 내용을 입력해도 매번 다른 결과가 나올 수 있다. 


# 파이프라인에 Hub 모델 적용하기


**distilgpt2** 모델 사용 -> 어떤 모델인지는 나중에 정리

# Inference(추론) API

모든 모델은 허깅페이스 웹사이트에서 제공하는 추론 API를 통해 브라우저 상에서 테스트 가능


# Mask filling(마스크 채우기)

```
from transformers import pipeline

unmasker = pipeline("fill-mask")
unmasker("This course will teach you all about <mask> models.", top_k=2)
```

**실행 결과**

```
[{'sequence': 'This course will teach you all about mathematical models.',
  'score': 0.19619831442832947,
  'token': 30412,
  'token_str': ' mathematical'},
 {'sequence': 'This course will teach you all about computational models.',
  'score': 0.04052725434303284,
  'token': 38163,
  'token_str': ' computational'}]
```

상위 몇 개의 높은 확률을 띠는 토큰을 출력할지 top_k 인자를 통해 조절한다.

여기서 모델이 특이한 <mask> 단어를 채우는 것에 주목해아한다. 

이를 마스크 토큰(mask token)이라고 부른다. 

다른 마스크 채우기 모델들은 다른 형태의 마스크 토큰을 사용할 수 있기 때문에 다른 모델을 탐색할 때 항상 해당 모델의 마스크 단어가 무엇인지 확인해야한다. 

# Named entity recognition (개체명 인식)

모델이 입력 텍스트의 어느 부분이 사람, 장소, 기관 등과 같은 개체에 해당하는지 찾는 작업을 개체명 인식(NER)이라고 합니다. 

```
from transformers import pipeline

ner = pipeline("ner", grouped_entities=True)
ner("My name is Sylvain and I work at Hugging Face in Brooklyn.")
```

실행 결과

```
[{'entity_group': 'PER', 'score': 0.99816, 'word': 'Sylvain', 'start': 11, 'end': 18},
 {'entity_group': 'ORG', 'score': 0.97960, 'word': 'Hugging Face', 'start': 33, 'end': 45},
 {'entity_group': 'LOC', 'score': 0.99321, 'word': 'Brooklyn', 'start': 49, 'end': 57}
]
```

# 질의 응답(Question-answering)

질의 응답 파이프라인은 주어진 지문(context)의 정보를 활용하여 질문에 대한 답을 하는 태스크다. 

```
from transformers import pipeline

question_answerer = pipeline("question-answering")
question_answerer(
    question="Where do I work?",
    context="My name is Sylvain and I work at Hugging Face in Brooklyn",
)
```

실행 결과

```
{'score': 0.6385916471481323, 'start': 33, 'end': 45, 'answer': 'Hugging Face'}
```

# Summarization(요약)

요약은 참조 텍스트의 모든(혹은 대부부분의) 중요한 특징을 그래도 유지한 채 텍스트를 짧게 줄이는 작업이다. 

# Translation(번역)

```
from transformers import pipeline

translator = pipeline("translation", model="Helsinki-NLP/opus-mt-fr-en")
translator("Ce cours est produit par Hugging Face.")
```

실행 결과

```
[{'translation_text': 'This course is produced by Hugging Face.'}]
```

[트랜스포머 모델](https://huggingface.co/learn/nlp-course/ko/chapter1/3?fw=pt)


# Gradio




