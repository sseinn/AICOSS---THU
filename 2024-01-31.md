# hypterparameters

- describe possible adjustments for any ml-application

- force algorithmic behavior

- have a major impact on model performance and inference quality

- examples:

- learing rate, activation function, momentum, gamma-values, weight decay, kernel size, thresholds, probabilities, ect.

- number of hidden layers, tree depth, number of neurons, number of leaves, ect.

# why should you tune/optimize those parameters?

- improving model quality & performace

- trial & error is time-consuming(expensive)

- automatic documentation of experiments

- improved model insights(white box)

- building trust

# HPO-Evolution

1. not dealing withi iparameter tuning at all

2. manually optimizing parameters

3. utilizing grid search

# gudied optimization

# HPO-Frameworks(optuna)

  텐서플로, 케라스 등등...

# Optuna vocabulary

### Sampler

- strategy to sample set of parameters from given search space

- random search

- grid search

- bayesian optimization search(Tree-structured parzen estimator)

- meta-heuristic search

- custom search

### Pruner

- strategy to omit unpromising sets of parameters

  sampling : 하이퍼 파라미터를 설정하고 학습이 잘 되는지 확인함

# optuna vocab cont.

### study

- defines the experimental setup (e.g.:sampling & pruning strategy, optimization type)

  (study는 여러번의 시도)

### trial

- a single experiment within a study, using a selected set of patameters

### objective function

- provides feedback of the fitness(quality) of a model for a single trial(e.g.: accuracy)

### road map

1. framework basics

2. neural architecture search (NAS)

3. pruning

4. visualization


# Q. Framework 선택 기준이 있냐?

A. 없다. 개인의 선택 

# framework 비교

이 frameworm를 얼마나 더 유지가능 하냐

전반적으로 순위룰 매겨봤는데 optuna가 가장 best였다...


# Application & Data

- Fetal health classification

- Dataset on kaggle

- Cardiotocography data from unborn childernindicates heart health)

- 2126 samples, 21 features, 1 target(fetal health)

- classes:

  - normal
 
  - suspect : heart diseases 의심
 
  - pathological : definately related to heart diseases
 
  - **data가 매우 unbalanced : normal data가 가장 많음**
 
- highly unbalanced

- cleaned & prepared

- proposed solution : multilayer perceptron classificatoin(feed forward artificial nerual network)


# initial multilayer perceptron

- input layer : 21 input neruons

- hidden layer 1: 15 neurons(variable)

- hidden layer : 10 neurons(variable)

- output layer : 3 output neurons

### workshop

- hyperparameter

  - weight_decay
 
  - null_accuracy : for unbalanced problem,

    만약 남자 7명 여자 3명이 있을 때, null_predict를 하면 남자라고 예측. 이때 null_predict의 accuracy가 null_accuracy가 된다. 
 


# optimizer 종류

- gradient descent

가장 기본이 되는 optimizer

GD는 경사를 따라 내려가면서 weight를 업데이트해 minimun 값을 찾는 방법이다. 

**단점**

1. 모든 자료의 기울기를 다 검토하기 때문에 데이터셋의 크기가 클수록 계산량이 너무 커진다.
2. 여기서 local minimum & global minimum 이라는 개념이 등장하는데, 전체에서 최소가 되는 부분인 global minimum을 찾는 것이 optimization의 목표 -> 그런데 local minimum을 찾았을 때 업데이트 과정이 끝난다.

3. 

