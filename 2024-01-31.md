# hypterparameters

- describe possible adjustments for any ml-application

- force algorithmic behavior

- have a major impact on model performance and inference quality

- examples:

- learing rate, activation function, momentum, gamma-values, weight decay, kernel size, thresholds, probabilities, ect.

- number of hidden layers, tree depth, number of neurons, number of leaves, ect.

# why should you tune/optimize those parameters?

- improving model quality & performace

- trial & error is time-consuming(expensive)

- automatic documentation of experiments

- improved model insights(white box)

- building trust
